training log record, random seed=777
dataset configuration: epoch size = 150, batch size = 16, patch size = 256
===> Epoch[1](30/150): Avg. Loss: 0.1749
===> Epoch[1](60/150): Avg. Loss: 0.1120
===> Epoch[1](90/150): Avg. Loss: 0.1055
===> Epoch[1](120/150): Avg. Loss: 0.0950
===> Epoch[1](150/150): Avg. Loss: 0.0808
===> Avg. PSNR: 19.0478 dB
===> Avg. Loss: 0.0854 dB
===> Epoch[2](30/150): Avg. Loss: 0.0793
===> Epoch[2](60/150): Avg. Loss: 0.0722
===> Epoch[2](90/150): Avg. Loss: 0.0676
===> Epoch[2](120/150): Avg. Loss: 0.0592
===> Epoch[2](150/150): Avg. Loss: 0.0562
===> Avg. PSNR: 24.1296 dB
===> Avg. Loss: 0.0501 dB
===> Epoch[3](30/150): Avg. Loss: 0.0604
===> Epoch[3](60/150): Avg. Loss: 0.0541
===> Epoch[3](90/150): Avg. Loss: 0.0556
===> Epoch[3](120/150): Avg. Loss: 0.0556
===> Epoch[3](150/150): Avg. Loss: 0.0521
===> Avg. PSNR: 22.6918 dB
===> Avg. Loss: 0.0586 dB
===> Epoch[4](30/150): Avg. Loss: 0.0554
===> Epoch[4](60/150): Avg. Loss: 0.0494
===> Epoch[4](90/150): Avg. Loss: 0.0492
